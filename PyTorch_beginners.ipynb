{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPB7RrKKtcz2D2ssb2mpxOb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reban87/PyTorch-Basics/blob/main/PyTorch_beginners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Crash Course\n",
        "### Overview\n",
        "1. Tensor Basics\n",
        "    - Create, Operations, NumPy, GPU Support\n",
        "2. Autograd\n",
        "    - Linear Regression Example\n",
        "3. Training loop with: Model Loss and Optimizer\n",
        "    - A typical PyTorch training pipeline\n",
        "4. Neural Network\n",
        "   - Also: GPU, Datasets, DataLoaders, Transforms and Evaluations\n",
        "5. CNN\n",
        "  - Save / Load Model\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "27jWN45oswi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tensors\n",
        "Everything is PyTorch is based on Tensor Operations. A Tensor is a multi-dimensional matrix containing element of a single data type:"
      ],
      "metadata": {
        "id": "daRBf_5DtpGj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1JJ9Fn7sj_9",
        "outputId": "cbf40f00-19e2-4617-864e-980128f9588b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty(1): tensor([5.5294e+12])\n",
            "empty(3): tensor([7.3061e-16, 3.1476e-41, 0.0000e+00])\n",
            "empty(2,3): tensor([[2.2300e+18, 3.1472e-41, 2.0852e+18],\n",
            "        [3.1472e-41, 1.1210e-43, 0.0000e+00]])\n",
            "empty(2,2,3): tensor([[[7.2980e-16, 3.1476e-41, 0.0000e+00],\n",
            "         [1.4013e-45, 8.9683e-44, 0.0000e+00]],\n",
            "\n",
            "        [[1.1210e-43, 0.0000e+00, 7.1007e-16],\n",
            "         [3.1476e-41, 0.0000e+00, 0.0000e+00]]])\n",
            "empty(2,2,3,4): tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 1.4013e-45,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  8.4078e-45,  0.0000e+00],\n",
            "          [ 1.4013e-45,  0.0000e+00, -1.7014e+38,  1.1515e-40]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6905e-43,  0.0000e+00,  1.1210e-43,  0.0000e+00],\n",
            "          [ 7.2899e-16,  3.1476e-41,  5.5294e+12,  4.3362e-41],\n",
            "          [ 3.1389e-43,  0.0000e+00,  3.5873e-43,  0.0000e+00]],\n",
            "\n",
            "         [[ 1.9763e+18,  3.1472e-41,  2.7465e-43,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  9.1084e-44,  0.0000e+00]]]])\n",
            "rand(1): tensor([0.7152])\n",
            "rand(3): tensor([0.9489, 0.8315, 0.0227])\n",
            "rand(2,3): tensor([[0.6559, 0.2422, 0.7037],\n",
            "        [0.6494, 0.5658, 0.4974]])\n",
            "zeros(5,3): tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "ones(5,3): tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# torch.empty(size): uninitialized\n",
        "x = torch.empty(1) #scalar\n",
        "print(\"empty(1):\", x)\n",
        "x = torch.empty(3) # vector\n",
        "print(\"empty(3):\", x)\n",
        "x = torch.empty(2 ,3) # matrix\n",
        "print(\"empty(2,3):\", x)\n",
        "x= torch.empty(2,2,3) # tensor 3 dimensions\n",
        "print(\"empty(2,2,3):\", x)\n",
        "x = torch.empty(2,2,3,4) # tensor 4 dimensions\n",
        "print(\"empty(2,2,3,4):\", x)\n",
        "\n",
        "# torch.rand(size): random numbers [0,1]\n",
        "x = torch.rand(1)\n",
        "print(\"rand(1):\", x)\n",
        "x = torch.rand(3)\n",
        "print(\"rand(3):\", x)\n",
        "x = torch.rand(2,3)\n",
        "print(\"rand(2,3):\", x)\n",
        "\n",
        "# torch.zeroes(size) , fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5,3)\n",
        "print(\"zeros(5,3):\", x)\n",
        "x = torch.ones(5,3)\n",
        "print(\"ones(5,3):\", x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the size of the Tensor\n",
        "print(x.size())\n",
        "print(\"shape:\",x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25aGv7nGuCZN",
        "outputId": "16573459-30af-455d-9b79-8430404c855d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "shape: torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.ones(5,3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzC4wKrbxBXC",
        "outputId": "e1269e7f-946e-407e-cb00-db53ab6677f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float16\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x, x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5A9KjkKxd3T",
        "outputId": "847c0a87-c330-4eb2-9936-733bd72160c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "# Suppose if I'm desining the position embedding, and i want to keep the position out of the training, then i can set it as False\n",
        "x = torch.tensor([5.5, 4], requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaHSEoMjx4VC",
        "outputId": "22eda88c-e087-467c-ce58-9e71edaa7b4f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 4.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operations with Tensors"
      ],
      "metadata": {
        "id": "0JcaAzu0zDCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Operations\n",
        "x = torch.ones(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "#element wise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# z = y.add_(x)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIrumsMXzLcK",
        "outputId": "ee22c181-e8f5-4129-fad5-39a8514a56fb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.1514, 0.8546],\n",
            "        [0.6015, 0.1006]])\n",
            "tensor([[1.1514, 1.8546],\n",
            "        [1.6015, 1.1006]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)"
      ],
      "metadata": {
        "id": "PfV2pSKpzmv5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing\n",
        "x  = torch.rand(5,3)\n",
        "print(x)\n",
        "print(\"x[:,0]\", x[:,0]) # all rows 0th column\n",
        "print(\"x[0, :]\", x[0, :]) # o row all column\n",
        "print(\"x[1,1]\", x[1,1]) # 1 row 1 column\n",
        "\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(\"x[1,1].item()\", x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2s-aajF0NAp",
        "outputId": "04dbe39b-7e33-4f00-e97d-36e769faa6f0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2326, 0.7650, 0.1902],\n",
            "        [0.7890, 0.1312, 0.7895],\n",
            "        [0.6212, 0.9069, 0.2796],\n",
            "        [0.2609, 0.1997, 0.6165],\n",
            "        [0.1663, 0.0283, 0.0931]])\n",
            "x[:,0] tensor([0.2326, 0.7890, 0.6212, 0.2609, 0.1663])\n",
            "x[0, :] tensor([0.2326, 0.7650, 0.1902])\n",
            "x[1,1] tensor(0.1312)\n",
            "x[1,1].item() 0.13119006156921387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is very easy"
      ],
      "metadata": {
        "id": "fAI-LVuC1Ej5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to NumPy with .numpy()\n",
        "b  = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwE8SM9t0Yoa",
        "outputId": "bd0b09ba-7bc2-48f4-e220-c0e3a14c5529"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Careful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA0nLhId1Q8h",
        "outputId": "cdec5744-ebcd-4b95-81a5-141e708b2425"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHrsc0sv1nFY",
        "outputId": "f3c6f6e2-1933-4ea1-b763-272dd80b7fe2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU Support\n",
        "By default all tensors are created on the CPU. But we can also move them to the GPU (if it's available ), or create them directly on the GPU."
      ],
      "metadata": {
        "id": "6J0z8R8c2Fd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAqwjNaK2KVA",
        "outputId": "b849b755-8193-484a-877a-7b7719c4b2b2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2).to(device) # move tensors to GPU device\n",
        "# x = x.to(\"cpu\")\n",
        "x = x.to(\"cuda\")\n",
        "print(x)\n",
        "\n",
        "x = torch.rand(2,2, device=device)  # or directy create them on GPU\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-SQHjMo2NV5",
        "outputId": "7a93de71-eb6d-49c4-d51e-bb01cdd04262"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.6914],\n",
            "        [0.7331, 0.2176]], device='cuda:0')\n",
            "tensor([[0.9149, 0.6454],\n",
            "        [0.4184, 0.7588]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Autograd\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. Generally speaking, torch.autograd is an engine for computing the vector-Jacobian product. It computes partial derivates while applying the chain rule.\n",
        "\n",
        "Set `requires_grad = True`:"
      ],
      "metadata": {
        "id": "GW6c1hTi23yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True) # torch.randn will generate random number which follows normal distribution\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj3czGMk2ccB",
        "outputId": "abc3de10-dab6-4343-ed00-efb9a0e4a951"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.4742,  1.7714, -0.1978], requires_grad=True)\n",
            "tensor([3.4742, 3.7714, 1.8022], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x78df5984bb20>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lWZvueBAVpe",
        "outputId": "3d4c158c-65ec-4246-ff5c-da71001559b7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36.2093, 42.6714,  9.7439], grad_fn=<MulBackward0>)\n",
            "tensor(29.5415, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# !!! Careful!!! backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!! optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0-52SLrAmjl",
        "outputId": "6d2a70b3-77fb-491c-c765-4da6e3fd4e99"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([6.9483, 7.5429, 3.6044])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop a tensor from tracking history\n",
        "For example during the training loop when we want to update our weights, or after training during evaluation. These operations should not be part of the gradient computation. To prevent this, we can use:\n",
        "\n",
        "- `x.requires_grad_(False)`\n",
        "- `x.detach()`\n",
        "- wrap in `with torch.no_grad():`"
      ],
      "metadata": {
        "id": "m_J2kn29AxW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_xiPZ8A23s",
        "outputId": "f4ecdc93-e257-4bad-9862-0e2347ad39cb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x78df598870d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "b = a.detach()\n",
        "print(a.requires_grad)\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXjRdnFLA9tF",
        "outputId": "c85ac4ff-547b-4417-9774-b38c9a3e2a75"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    b = a ** 2\n",
        "    print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ne0Hp_gBJgt",
        "outputId": "7258d4ef-6e29-47a8-9fad-393bd3a3304e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    }
  ]
}